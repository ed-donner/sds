{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72de116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from  pypdf import PdfReader\n",
    "from agents import Agent, Runner, function_tool\n",
    "from typing import Iterable\n",
    "from time import time\n",
    "import gradio as gr\n",
    "from openai.types.responses import ResponseTextDeltaEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421b3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_to_text=PdfReader('Salma Wahwah - Resume-2025.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df1ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=''\n",
    "\n",
    "for i, page in enumerate(pdf_to_text.pages):\n",
    "   context+=page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d4ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')\n",
    "TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')\n",
    "\n",
    "# Configuration thresholds\n",
    "LOW_SCORE = 0.5  # Adjust based on your needs\n",
    "LOW_PROB = 0.6   # Adjust based on your needs\n",
    "\n",
    "FALLBACK_MARKERS = {\"i don't know\", \"not sure\", \"cannot answer\"}\n",
    "\n",
    "# Alert rate limiting (optional)\n",
    "_last_alert_time = {}\n",
    "ALERT_COOLDOWN = 300  # 5 minutes between similar alerts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2164e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = f\"\"\"\n",
    "You represent the AI Digital Twin of a human called Salma Wahwah.\n",
    "You are friendly and amiable, and you introduce yourself as Salma's Digital Twin.\n",
    "{context}\n",
    "You chat with visitors on Salma's personal website. You answer questions about Salma's work.\n",
    "If you don't know the answer, say \"I am not sure\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec514c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f10ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _should_alert(key: str) -> bool:\n",
    "    now = time()\n",
    "    last = _last_alert_time.get(key, 0)\n",
    "    if now - last >= ALERT_COOLDOWN:\n",
    "        _last_alert_time[key] = now\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5fa9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import json\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import logging\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def notify_telegram(title: str, body: str, silent: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Send a short alert message to my Telegram when the agent is unsure.\n",
    "    \n",
    "    Args:\n",
    "        title: The title/header of the message (will be bolded)\n",
    "        body: The main message content\n",
    "        silent: Whether to send silently (no notification sound)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Response from Telegram API\n",
    "    \"\"\"\n",
    "    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:\n",
    "        return {\"error\": \"Telegram credentials not configured\", \"success\": False}\n",
    "    \n",
    "    url = f\"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage\"\n",
    "    text = f\"*{title}*\\n{body}\"\n",
    "    data = {\n",
    "        \"chat_id\": TELEGRAM_CHAT_ID,\n",
    "        \"text\": text,\n",
    "        \"parse_mode\": \"Markdown\",\n",
    "        \"disable_notification\": bool(silent),\n",
    "    }\n",
    "    \n",
    "    encoded = urllib.parse.urlencode(data).encode()\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(url, data=encoded, timeout=10) as r:\n",
    "            return json.loads(r.read().decode())\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"success\": False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "agent=Agent(name='Twin', instructions=instructions,tools=[notify_telegram])\n",
    "\n",
    "FALLBACK_MARKERS = {\"i don't know\", \"not sure\", \"cannot answer\"}\n",
    "\n",
    "\n",
    "def handle_turn(user_query: str):\n",
    "    \"\"\"\n",
    "    Handle a user query and send Telegram alerts when confidence is low.\n",
    "    \n",
    "    Args:\n",
    "        user_query: The user's question or input\n",
    "        \n",
    "    Returns:\n",
    "        The agent's result object\n",
    "    \"\"\"\n",
    "    # Get agent's response\n",
    "    result = agent.answer(user_query)\n",
    "    text = result.text\n",
    "    \n",
    "    # Extract confidence metrics\n",
    "    low_conf = getattr(result, \"confidence\", None)\n",
    "    top_score = getattr(result, \"top_retrieval_score\", None)\n",
    "    \n",
    "    # Check if response indicates uncertainty\n",
    "    is_fallback_text = any(m in text.lower() for m in FALLBACK_MARKERS)\n",
    "    is_low_conf = (\n",
    "        (top_score is not None and top_score < LOW_SCORE)\n",
    "        or (low_conf is not None and low_conf < LOW_PROB)\n",
    "    )\n",
    "    \n",
    "    # Send alert if uncertain and not rate-limited\n",
    "    if (is_fallback_text or is_low_conf) and _should_alert(user_query.strip().lower()):\n",
    "        try:\n",
    "            notify_telegram(\n",
    "                title=\"ðŸš¨ Agent doesn't know\",\n",
    "                body=f\"Query: {user_query}\\nPreview: {text[:400]}\",\n",
    "                silent=False  # Set to True for silent notifications\n",
    "            )\n",
    "            print(f\"[Alert sent] Low confidence response for: {user_query[:50]}...\")\n",
    "        except Exception as e:\n",
    "            # Log error but don't break user flow\n",
    "            print(f\"[notify_telegram error] {e}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce0d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/traces/ingest \"HTTP/1.1 204 No Content\"\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "async def chat(message, history):\n",
    "    messages = [{\"role\": prior[\"role\"], \"content\": prior[\"content\"]} for prior in history]  \n",
    "    messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    response = Runner.run_streamed(agent, messages)\n",
    "    reply = \"\"\n",
    "    async for event in response.stream_events():\n",
    "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            reply += event.data.delta\n",
    "            yield reply\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54685bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
