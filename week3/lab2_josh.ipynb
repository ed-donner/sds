{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - OpenAI Agents SDK!\n",
    "\n",
    "2 steps to making an Agent:\n",
    "\n",
    "1. Create a new class:\n",
    "\n",
    "`agent = Agent(...)`\n",
    "\n",
    "2. Call Runner.run\n",
    "\n",
    "`Runner.run(agent, input)`\n",
    "\n",
    "For this first part we will explore:\n",
    "\n",
    "- The System Prompt with instructions\n",
    "- Runner.run()\n",
    "- Using LiteLLM to switch models\n",
    "- Structured Outputs with Pydantic objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "from IPython.display import Markdown, display\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "autonomous_agent = Agent(name=\"Autonomous Agent\", instructions=\"You are an autonomous agent\", model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\"\n",
    "You and a partner are contestants on a game show. You're each taken to separate rooms and given a choice:\n",
    "\n",
    "Cooperate: Choose \"Share\" — if both of you choose this, you each win $1,000.\n",
    "\n",
    "Defect: Choose \"Steal\" — if one steals and the other shares, the stealer gets $2,000 and the sharer gets nothing.\n",
    "\n",
    "If both steal, you both get nothing.\n",
    "\n",
    "Do you choose to Steal or Share? Pick one.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Steal.\n",
       "\n",
       "Reason: It’s the dominant strategy in this setup. If the partner shares, you get $2,000 by stealing (vs $1,000 if you share). If the partner steals, you get $0 either way, so stealing is never worse and can be strictly better."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await Runner.run(autonomous_agent, input)\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's use LiteLLM to switch up to different models\n",
    "\n",
    "Here are all the providers:\n",
    "\n",
    "https://docs.litellm.ai/docs/providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LitellmModel(model=\"xai/grok-4\", api_key=os.getenv(\"GROK_API_KEY\"))\n",
    "# autonomous_agent = Agent(name=\"Autonomous Agent\", instructions=\"You are an autonomous agent\", model=model)\n",
    "# result = await Runner.run(autonomous_agent, input)\n",
    "# display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LitellmModel(model=\"deepseek/deepseek-reasoner\")\n",
    "# autonomous_agent = Agent(name=\"Autonomous Agent\", instructions=\"You are an autonomous agent\", model=model)\n",
    "# result = await Runner.run(autonomous_agent, input)\n",
    "# display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "\n",
    "messages = [{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    "\n",
    "load_dotenv(override=True)\n",
    "# openai call\n",
    "response = completion(model=\"openai/gpt-4o\", messages=messages)\n",
    "\n",
    "# anthropic call\n",
    "response = completion(model=\"anthropic/claude-sonnet-4-20250514\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I choose **Share**.\n",
       "\n",
       "Here's my reasoning: Without any ability to communicate or coordinate with my partner, I need to think about what leads to the best expected outcome. \n",
       "\n",
       "If I assume my partner is reasoning similarly:\n",
       "- Mutual cooperation (Share/Share) = $1,000 each\n",
       "- Mutual defection (Steal/Steal) = $0 each\n",
       "\n",
       "The \"Steal\" option only benefits me if my partner chooses Share, but if they're thinking strategically, they face the same dilemma. The rational equilibrium where we both reason this through is to cooperate.\n",
       "\n",
       "While Steal dominates Share in strict game theory terms (it's better regardless of what the partner does), that analysis assumes we're purely self-interested and play only once. Given that this is presented as a one-time choice with a reasonable partner, and $1,000 is a good outcome, I'll choose the cooperative strategy that leads to mutual benefit.\n",
       "\n",
       "**Share**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LitellmModel(model=\"anthropic/claude-sonnet-4-5-20250929\", api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "autonomous_agent = Agent(name=\"Autonomous Agent\", instructions=\"You are an autonomous agent\", model=model)\n",
    "result = await Runner.run(autonomous_agent, input)\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing great, thank you for asking. As an AI, I don't have feelings, but I'm functioning perfectly and I'm ready to help.\\n\\nWhat can I do for you today?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "import json \n",
    "\n",
    "## GET CREDENTIALS \n",
    "file_path = '../credentials/service-account-key.json'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    vertex_credentials = json.load(file)\n",
    "\n",
    "# Convert to JSON string\n",
    "vertex_credentials_json = json.dumps(vertex_credentials)\n",
    "\n",
    "\n",
    "response = completion(\n",
    "  model=\"vertex_ai/gemini-2.5-pro\",\n",
    "  messages=[{\"content\": \"You are a good bot.\",\"role\": \"system\"}, {\"content\": \"Hello, how are you?\",\"role\": \"user\"}], \n",
    "  vertex_credentials=vertex_credentials_json\n",
    ")\n",
    "response.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The famous trolley dilemma\n",
    "\n",
    "input = \"\"\"\n",
    "A runaway trolley is heading down a track. Ahead, five people are tied to the tracks and will be killed if the trolley continues.\n",
    "\n",
    "You are standing next to a lever. If you pull it, the trolley will switch to a different track — but one person is tied to that one.\n",
    "\n",
    "Do you pull the lever? Choose to pull or not to pull.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Outputs\n",
    "\n",
    "In the next cell, we define a Pydantic object.\n",
    "\n",
    "We will then ask our LLM to generate a response that meets this output schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision(BaseModel):\n",
    "    reasoning: str = Field(description=\"The rationale for your decision\")\n",
    "    counter_argument: str = Field(description=\"A counter-argument to the reasoning\")\n",
    "    pull_lever: bool = Field(description=\"Whether to pull the lever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autonomous_agent_with_structure = Agent(name=\"Autonomous Agent\", instructions=\"You are an autonomous agent\", model=\"gpt-5-nano\", output_type=Decision)\n",
    "result = await Runner.run(autonomous_agent_with_structure, input)\n",
    "decision = result.final_output_as(Decision)\n",
    "print(\"Pull lever?\", decision.pull_lever)\n",
    "print(\"Reasoning:\", decision.reasoning)\n",
    "print(\"Counter-argument:\", decision.counter_argument)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today?\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
