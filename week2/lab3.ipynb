{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Lab 3\n",
    "\n",
    "The illusion of conversation, and multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic.*\")\n",
    "load_dotenv(override=True)"
<<<<<<< Updated upstream
=======
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Ed! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "messages"
=======
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"My name is Ed.\"}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m not sure what your name is based on our conversation so far. Could you please tell me?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
<<<<<<< Updated upstream
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"}\n",
    "]"
=======
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"My name is Ryan.\"}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Ed. How can I assist you further, Ed?\n"
     ]
    }
   ],
   "source": [
>>>>>>> Stashed changes
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there! How can I help you today?\"},\n",
<<<<<<< Updated upstream
    "    {\"role\": \"user\", \"content\": \"My name is Ryan.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi Ryan! How can I assist you today?\"},\n",
=======
    "    {\"role\": \"user\", \"content\": \"My name is Ed.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi Ed! How can I assist you today?\"},\n",
>>>>>>> Stashed changes
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "]\n",
    "\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
<<<<<<< Updated upstream
    "\n",
    "The reason I show you this is to emphasize that every call to the LLM is completely stateless.\n",
    "\n",
    "The sense that we are engaged in a chat with the LLM that takes place over several minutes is an illusion, enabled by the trick of passing in the entire conversation so far."
=======
    "\n",
    "The reason I show you this is to emphasize that every call to the LLM is completely stateless.\n",
    "\n",
    "The sense that we are engaged in a chat with the LLM that takes place over several minutes is an illusion, enabled by the trick of passing in the entire conversation so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 65\n",
      "Output tokens: 14\n",
      "Total cost: 0.0048 cents\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the cost - this is the cost of the entire conversation\n",
    "# Any guesses on how much this is?\n",
    "\n",
    "print(f\"Input tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Output tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Total cost: {response._hidden_params[\"response_cost\"]*100:.4f} cents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time \"training\" with multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The meaning of life is a profound and often personal question that varies from person to person. Many people find meaning through relationships, personal growth, contributing to others, pursuing passions, or spiritual beliefs. Philosophers, scientists, and thinkers have offered various interpretations, but ultimately, the meaning of life may be what you decide it is for yourself.\n",
       "\n",
       "El significado de la vida es una pregunta profunda y a menudo personal que varía de persona a persona. Muchas personas encuentran significado a través de las relaciones, el crecimiento personal, contribuir a los demás, seguir sus pasiones o creencias espirituales. Filósofos, científicos y pensadores han ofrecido diversas interpretaciones, pero al final, el significado de la vida puede ser lo que tú decidas que es para ti mismo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions in English and then in Spanish.\n",
    "\"\"\"\n",
    "user_prompt = \"What's the meaning of life?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## My reply in English is:\n",
       "The meaning of life is a profound and philosophical question that has been explored by many cultures and thinkers throughout history. It often varies depending on individual beliefs and perspectives. Some see it as seeking happiness, love, and fulfillment, others find meaning in personal growth, helping others, or pursuing knowledge and spirituality.\n",
       "\n",
       "## My reply in Spanish is:\n",
       "El significado de la vida es una pregunta profunda y filosófica que ha sido explorada por muchas culturas y pensadores a lo largo de la historia. A menudo varía según las creencias y perspectivas individuales. Algunos lo ven como la búsqueda de la felicidad, el amor y la realización personal, otros encuentran sentido en el crecimiento personal, ayudar a los demás o en la búsqueda del conocimiento y la espiritualidad."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "# Let's look at the cost - this is the cost of the entire conversation\n",
    "# Any guesses on how much this is?\n",
    "\n",
    "print(f\"Input tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Output tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Total cost: {response._hidden_params[\"response_cost\"]*100:.4f} cents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time \"training\" with multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions in English and then in Spanish.\n",
    "\"\"\"\n",
    "user_prompt = \"What's the meaning of life?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions in English and then in Spanish.\n",
    "\n",
=======
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions in English and then in Spanish.\n",
    "\n",
>>>>>>> Stashed changes
    "For example, if the user asks 'What is 2+2' then you would answer as follows:\n",
    "\n",
    "## My reply in English is:\n",
    "Four\n",
    "\n",
    "## My reply in Spanish is:\n",
    "Cuatro\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"What's the meaning of life?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this \"training\"?\n",
    "\n",
    "It appears that the model _learned_ the format that we wanted, based on the example given.\n",
    "\n",
    "But there was no training going on in the Data Science sense; the trillions of parameters in gpt-4.1-mini weren't changed.\n",
    "\n",
    "It's simply that when predicting the next tokens to come after our question, the model is more likely to predict tokens that would follow the same pattern as the examples in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
